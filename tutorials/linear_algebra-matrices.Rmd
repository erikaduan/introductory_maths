---
title: Introduction to matrices     
author: Erika Duan
date: "`r Sys.Date()`"
output:
  github_document:
    toc: true
    toc_depth: 2
    math_method:
      engine: webtex
      url: https://latex.codecogs.com/svg.format?
---

```{r setup, include=FALSE}
# Set up global environment configuration --------------------------------------
knitr::opts_chunk$set(echo=TRUE,
                      results='hide',
                      fig.show='hold',
                      fig.align='center',
                      message=FALSE,
                      warning=FALSE,
                      out.width='80%')

knitr::knit_engines$set(python = reticulate::eng_python)
```

```{r, echo=FALSE}
# Install R packages -----------------------------------------------------------
# The native pipe operator requires R version 4.1+ 
packages <- c("ggplot2",
              "dplyr")

installed_packages <- packages %in% rownames(installed.packages())

if (any(installed_packages == FALSE)) {
  install.packages(packages[!installed_packages])
}

# Attach R packages to the global environment
library("dplyr")
library("ggplot2")

# Check version of Python used by reticulate -----------------------------------
reticulate::py_config()
```


# Matrices      
A matrix with $m$ rows and $n$ columns can be used to hold the coefficients from any linear system $A\vec x = \vec b$.   

For any homogeneous linear system with linearly independent vectors $\vec a_1, \vec a_2, \cdots, \vec a_p$, each vector represents a scalable basis vector and $\{\vec a_1, \vec a_2, \cdots, \vec a_p\}$ spans subspace H, where subspace H has $p$ dimensions.    

```{r, echo=FALSE, results='markup'}
knitr::include_graphics("../figures/linear_systems-matrix_transformations.svg")
```


# Types of matrices   
Types of matrices include:  

+ Transpose matrix: If matrix A has dimensions $m\times n$, then its transpose matrix $A^T$ has dimensions $n \times m$ and every row of A is a column in $A^T$.  
+ Zero matrix: a matrix in which every entry is 0.   
+ Symmetrical matrix: a matrix where values on either side of the diagonal are equal to each other. Symmetrical matrices therefore have the property $A^T = A$.      
+ Identity matrix: a matrix with dimensions $m \times m$ where each diagonal entry is 1 and all other entries are 0.   

```{r, echo=FALSE, results='markup'}
knitr::include_graphics("../figures/linear_systems-matrix_types.svg")
```


# Matrix column space   
For any $m\times n$ matrix A, $A = \begin{bmatrix} \vec a_1 & \vec a_2 & \cdots & \vec a_n \end{bmatrix}$. The column space of A, denoted as $ColA$, is therefore the span of $\{\vec a_1, \vec a_2, \cdots, \vec a_n\}$.     

Therefore $ColA = \{\vec b \in \mathbb{R}^m | A\vec x = \vec b \,for \,some \, \vec x \in \mathbb{R}^n\}$.    

$ColA$ is also the subspace of $\mathbb{R}^m$ which is spanned by the basis vectors $\{\vec a_1, \vec a_2, \cdots, \vec a_p\}$ or pivot columns of matrix A.   

```{r, echo=FALSE, results='markup'}
knitr::include_graphics("../figures/linear_systems-matrix_column_space.svg")
```


# Matrix null space   
For any $m\times n$ matrix A, the null space of A, denoted as $NulA$, is the set of all solutions to the homogeneous linear system $A\vec x=\vec 0$.  

Therefore $NulA = \{\vec x \in \mathbb{R}^n | A\vec x = \vec 0\}$.   

As homogeneous linear systems have either a single trivial solution or infinite solutions, $NulA$ is either $\vec 0$ or a subspace of $\mathbb{R}^n$.   

When $A\vec x=\vec 0$ has infinite solutions, $NulA$ can also be expressed in the parametric form $c_1\vec v_1 + c_2\vec v_2 + \cdots + c_n\vec v_h$ as $Span\{\vec v_1, \vec v_2, \cdots, \vec v_h\}$.   

```{r, echo=FALSE, results='markup'}
knitr::include_graphics("../figures/linear_systems-matrix_null_space.svg")
```

In summary:   

+ $ColA$ represents the span of the basis vectors of matrix A.  
+ $NulA$ represents the set of all possible solutions to $A \vec x = \vec 0$. When the solution is presented in parametric form (when there are infinite solutions to $A\vec x = \vec 0$), $NulA$ also has a vector span in relation to its free variables.       

```{r, echo=FALSE, results='markup'}
knitr::include_graphics("../figures/linear_systems-matrix_rank_and_nullity.svg")
```

**Note:** Using examples of homogeneous linear systems, we can see that the number of column vectors in matrix A, represented as $n$, is equal to the sum of the dimensions of $ColA$ and the dimensions of $NulA$.   


# Matrix scalar multiplication   
This property is useful for further defining the properties of linear transformations, which is covered in the next tutorial on linear transformations.    

```{r, echo=FALSE, results='markup'}
knitr::include_graphics("../figures/linear_systems-matrix_scalar_multiplication.svg")
```


# Matrix addition  
Some of the most useful properties of matrix addition include:    

+ That $A + B = B + A$. This shows that the order of matrix addition does not matter.  
+ That $k(A + B) = kA + kB$. This shows that the scalar transformation of the sum of matrices A and B is identical to the sum of the scalar transformation of A and the scalar transformation of B. This is also crucial for defining the properties of linear transformations.     

```{r, echo=FALSE, results='markup'}
knitr::include_graphics("../figures/linear_systems-matrix_addition.svg")
```


# Matrix multiplication   
Unlike matrix addition, the order of matrix multiplication impacts the matrix multiplication product and $A \times B \neq B \times A$.   

Matrix multiplication has extra special meaning in linear algebra as it represents the sequence of linear transformations applied to any vector $\vec v$, where $\vec v \in \mathbb{R}^n$.   

```{r, echo=FALSE, results='markup'}
knitr::include_graphics("../figures/linear_systems-matrix_multiplication.svg")
```


# Finding the inverse matrix     
A matrix with dimensions $n \times n$ is invertible if it has an inverse form such that $A\times A^{-1} = I$ and $(A^{-1})^{-1} = A$, where $I$ is the identity matrix. Therefore a matrix is invertible if matrix $A$ is row equivalent to its identify matrix $I$ and any finite sequence of elementary row operations that transforms $A$ to $I$ also transforms $I$ to $A^{-1}$.      

The matrix inverse can be thought of as a matrix form of the multiplication inverse $\tfrac{1}{k}$ where $k \times \tfrac{1}{k} = 1$.   

The connection between linear systems and invertible matrices is that the linear system $A\vec x = \vec b$ has a unique solution if matrix A is invertible. This occurs as $A^{-1}A \vec x = \vec b$ can be simplified to $\vec x = A^{-1} \vec b$.    

In the algorithm for finding the inverse matrix $A^{-1}$, we aim to:  

1. Write down the augmented matrix $\left[\begin{array}{c|c}A&I_n\end{array}\right]$.      
2. Row reduce the augmented matrix until its left-hand side is in reduced echelon form. Let this be the result $\left[\begin{array}{c|c}B&C\end{array}\right]$.    
3. If $B = I_n$, then the right-hand side of the augmented matrix is the inverse matrix $A^{-1}$ i.e. $C=A^{-1}$. If the left-hand side cannot be simplified to a reduced echelon form, then matrix A is not invertible.   

```{r, echo=FALSE, results='markup'}
knitr::include_graphics("../figures/linear_systems-inverse_matrix.svg")
```

**Note:** If matrix A is row equivalent to the identity matrix $I_n$, then A must have $n$ pivot columns and the equation $A\vec x = \vec 0$  must only contain the trivial solution $x_1 = x_2 = \cdots = x_n = 0$.    

**Note:** A matrix that is not invertible is also called a singular matrix. An invertible matrix is also called a non-singular matrix.    


# Resources   
+ A great [YouTube video](https://www.youtube.com/watch?v=kYB8IZa5AuE&list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab&index=3) introducing matrices by 3Blue1Brown.  
+ A great [YouTube video](https://www.youtube.com/watch?v=XkY2DOUCWMU&list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab&index=4) explaining the purpose of matrix multiplication by 3Blue1Brown.   
+ A [clear explanation](https://math.stackexchange.com/questions/664594/why-mathbf0-has-dimension-zero) of why the set containing only the zero vector has 0 dimensions.   